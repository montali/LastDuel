{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/montali/LastDuel/blob/main/regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost keras_tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGYVT3jYhq-5",
        "outputId": "91e9cf72-f62a-41c2-c75a-da17bdb349f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: keras_tuner in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (2.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (2.23.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (5.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (21.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (1.0.4)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras_tuner) (0.2.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras_tuner) (0.7.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras_tuner) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras_tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras_tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras_tuner) (3.0.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.44.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (3.17.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras_tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras_tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras_tuner) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras_tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras_tuner) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras_tuner) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras_tuner) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras_tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras_tuner) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6SJsw97rhooV"
      },
      "outputs": [],
      "source": [
        "import catboost\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "xTqTKAJBhooY",
        "outputId": "879643fd-76ad-4369-b3a0-0bf0f98a9fa7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  average_ensemble  average_mlp  ensemble_mlp_diffn  \\\n",
              "0         1          0.958916     0.928211            0.030705   \n",
              "1         2          0.907264     0.967613           -0.060349   \n",
              "2         3          0.978562     0.954068            0.024494   \n",
              "3         3          0.978562     0.954068            0.024494   \n",
              "4         3          0.978562     0.954068            0.024494   \n",
              "...     ...               ...          ...                 ...   \n",
              "3295  10074          0.962136     0.831715            0.130421   \n",
              "3296  10075          0.968608     0.918447            0.050162   \n",
              "3297  10076          0.947977     0.950162           -0.002184   \n",
              "3298  10077          0.917476     0.871845            0.045631   \n",
              "3299  10079          0.925162     0.919741            0.005421   \n",
              "\n",
              "      AutoCorrelation  CfsSubsetEval_DecisionStumpAUC  \\\n",
              "0            0.606466                        0.981204   \n",
              "1            0.606466                        0.906774   \n",
              "2            0.999061                        0.961912   \n",
              "3            0.999061                        0.961912   \n",
              "4            0.999061                        0.961912   \n",
              "...               ...                             ...   \n",
              "3295         0.987694                        0.957609   \n",
              "3296         0.987694                        0.909885   \n",
              "3297         0.987694                        0.618161   \n",
              "3298         0.987694                        0.752021   \n",
              "3299         0.987694                        0.711715   \n",
              "\n",
              "      CfsSubsetEval_DecisionStumpErrRate  CfsSubsetEval_DecisionStumpKappa  \\\n",
              "0                               0.023385                          0.941800   \n",
              "1                               0.132517                          0.619102   \n",
              "2                               0.059136                          0.881192   \n",
              "3                               0.059136                          0.881192   \n",
              "4                               0.059136                          0.881192   \n",
              "...                                  ...                               ...   \n",
              "3295                            0.026537                          0.905922   \n",
              "3296                            0.025243                          0.825828   \n",
              "3297                            0.056958                          0.332928   \n",
              "3298                            0.094498                          0.569704   \n",
              "3299                            0.089968                          0.374492   \n",
              "\n",
              "      CfsSubsetEval_NaiveBayesAUC  CfsSubsetEval_NaiveBayesErrRate  ...  \\\n",
              "0                        0.981204                         0.023385  ...   \n",
              "1                        0.906774                         0.132517  ...   \n",
              "2                        0.961912                         0.059136  ...   \n",
              "3                        0.961912                         0.059136  ...   \n",
              "4                        0.961912                         0.059136  ...   \n",
              "...                           ...                              ...  ...   \n",
              "3295                     0.957609                         0.026537  ...   \n",
              "3296                     0.909885                         0.025243  ...   \n",
              "3297                     0.618161                         0.056958  ...   \n",
              "3298                     0.752021                         0.094498  ...   \n",
              "3299                     0.711715                         0.089968  ...   \n",
              "\n",
              "      RandomTreeDepth2AUC  RandomTreeDepth2ErrRate  RandomTreeDepth2Kappa  \\\n",
              "0                0.967172                 0.022272               0.943873   \n",
              "1                0.929700                 0.080178               0.795325   \n",
              "2                0.945136                 0.054443               0.890850   \n",
              "3                0.945136                 0.054443               0.890850   \n",
              "4                0.945136                 0.054443               0.890850   \n",
              "...                   ...                      ...                    ...   \n",
              "3295             0.902866                 0.056958               0.798384   \n",
              "3296             0.686802                 0.097087               0.365670   \n",
              "3297             0.515800                 0.089968               0.032195   \n",
              "3298             0.662674                 0.144984               0.333980   \n",
              "3299             0.609461                 0.115858               0.218120   \n",
              "\n",
              "      RandomTreeDepth3AUC  RandomTreeDepth3ErrRate  RandomTreeDepth3Kappa  \\\n",
              "0                0.967172                 0.022272               0.943873   \n",
              "1                0.929700                 0.080178               0.795325   \n",
              "2                0.945136                 0.054443               0.890850   \n",
              "3                0.945136                 0.054443               0.890850   \n",
              "4                0.945136                 0.054443               0.890850   \n",
              "...                   ...                      ...                    ...   \n",
              "3295             0.902866                 0.056958               0.798384   \n",
              "3296             0.686802                 0.097087               0.365670   \n",
              "3297             0.515800                 0.089968               0.032195   \n",
              "3298             0.662674                 0.144984               0.333980   \n",
              "3299             0.609461                 0.115858               0.218120   \n",
              "\n",
              "      StdvNominalAttDistinctValues  kNN1NAUC  kNN1NErrRate  kNN1NKappa  \n",
              "0                         1.502523  0.948265      0.030067    0.922629  \n",
              "1                         1.557606  0.872195      0.063474    0.826110  \n",
              "2                         0.164399  0.972843      0.069149    0.860968  \n",
              "3                         0.164399  0.972843      0.069149    0.860968  \n",
              "4                         0.164399  0.972843      0.069149    0.860968  \n",
              "...                            ...       ...           ...         ...  \n",
              "3295                      0.000000  0.952412      0.023948    0.913788  \n",
              "3296                      0.000000  0.850311      0.042071    0.707527  \n",
              "3297                      0.000000  0.661059      0.082201    0.271099  \n",
              "3298                      0.000000  0.661504      0.113269    0.382769  \n",
              "3299                      0.000000  0.762965      0.086731    0.470942  \n",
              "\n",
              "[3291 rows x 111 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35cfbc89-9112-4a9a-8d2e-376336d46272\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>average_ensemble</th>\n",
              "      <th>average_mlp</th>\n",
              "      <th>ensemble_mlp_diffn</th>\n",
              "      <th>AutoCorrelation</th>\n",
              "      <th>CfsSubsetEval_DecisionStumpAUC</th>\n",
              "      <th>CfsSubsetEval_DecisionStumpErrRate</th>\n",
              "      <th>CfsSubsetEval_DecisionStumpKappa</th>\n",
              "      <th>CfsSubsetEval_NaiveBayesAUC</th>\n",
              "      <th>CfsSubsetEval_NaiveBayesErrRate</th>\n",
              "      <th>...</th>\n",
              "      <th>RandomTreeDepth2AUC</th>\n",
              "      <th>RandomTreeDepth2ErrRate</th>\n",
              "      <th>RandomTreeDepth2Kappa</th>\n",
              "      <th>RandomTreeDepth3AUC</th>\n",
              "      <th>RandomTreeDepth3ErrRate</th>\n",
              "      <th>RandomTreeDepth3Kappa</th>\n",
              "      <th>StdvNominalAttDistinctValues</th>\n",
              "      <th>kNN1NAUC</th>\n",
              "      <th>kNN1NErrRate</th>\n",
              "      <th>kNN1NKappa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.958916</td>\n",
              "      <td>0.928211</td>\n",
              "      <td>0.030705</td>\n",
              "      <td>0.606466</td>\n",
              "      <td>0.981204</td>\n",
              "      <td>0.023385</td>\n",
              "      <td>0.941800</td>\n",
              "      <td>0.981204</td>\n",
              "      <td>0.023385</td>\n",
              "      <td>...</td>\n",
              "      <td>0.967172</td>\n",
              "      <td>0.022272</td>\n",
              "      <td>0.943873</td>\n",
              "      <td>0.967172</td>\n",
              "      <td>0.022272</td>\n",
              "      <td>0.943873</td>\n",
              "      <td>1.502523</td>\n",
              "      <td>0.948265</td>\n",
              "      <td>0.030067</td>\n",
              "      <td>0.922629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.907264</td>\n",
              "      <td>0.967613</td>\n",
              "      <td>-0.060349</td>\n",
              "      <td>0.606466</td>\n",
              "      <td>0.906774</td>\n",
              "      <td>0.132517</td>\n",
              "      <td>0.619102</td>\n",
              "      <td>0.906774</td>\n",
              "      <td>0.132517</td>\n",
              "      <td>...</td>\n",
              "      <td>0.929700</td>\n",
              "      <td>0.080178</td>\n",
              "      <td>0.795325</td>\n",
              "      <td>0.929700</td>\n",
              "      <td>0.080178</td>\n",
              "      <td>0.795325</td>\n",
              "      <td>1.557606</td>\n",
              "      <td>0.872195</td>\n",
              "      <td>0.063474</td>\n",
              "      <td>0.826110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.978562</td>\n",
              "      <td>0.954068</td>\n",
              "      <td>0.024494</td>\n",
              "      <td>0.999061</td>\n",
              "      <td>0.961912</td>\n",
              "      <td>0.059136</td>\n",
              "      <td>0.881192</td>\n",
              "      <td>0.961912</td>\n",
              "      <td>0.059136</td>\n",
              "      <td>...</td>\n",
              "      <td>0.945136</td>\n",
              "      <td>0.054443</td>\n",
              "      <td>0.890850</td>\n",
              "      <td>0.945136</td>\n",
              "      <td>0.054443</td>\n",
              "      <td>0.890850</td>\n",
              "      <td>0.164399</td>\n",
              "      <td>0.972843</td>\n",
              "      <td>0.069149</td>\n",
              "      <td>0.860968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.978562</td>\n",
              "      <td>0.954068</td>\n",
              "      <td>0.024494</td>\n",
              "      <td>0.999061</td>\n",
              "      <td>0.961912</td>\n",
              "      <td>0.059136</td>\n",
              "      <td>0.881192</td>\n",
              "      <td>0.961912</td>\n",
              "      <td>0.059136</td>\n",
              "      <td>...</td>\n",
              "      <td>0.945136</td>\n",
              "      <td>0.054443</td>\n",
              "      <td>0.890850</td>\n",
              "      <td>0.945136</td>\n",
              "      <td>0.054443</td>\n",
              "      <td>0.890850</td>\n",
              "      <td>0.164399</td>\n",
              "      <td>0.972843</td>\n",
              "      <td>0.069149</td>\n",
              "      <td>0.860968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0.978562</td>\n",
              "      <td>0.954068</td>\n",
              "      <td>0.024494</td>\n",
              "      <td>0.999061</td>\n",
              "      <td>0.961912</td>\n",
              "      <td>0.059136</td>\n",
              "      <td>0.881192</td>\n",
              "      <td>0.961912</td>\n",
              "      <td>0.059136</td>\n",
              "      <td>...</td>\n",
              "      <td>0.945136</td>\n",
              "      <td>0.054443</td>\n",
              "      <td>0.890850</td>\n",
              "      <td>0.945136</td>\n",
              "      <td>0.054443</td>\n",
              "      <td>0.890850</td>\n",
              "      <td>0.164399</td>\n",
              "      <td>0.972843</td>\n",
              "      <td>0.069149</td>\n",
              "      <td>0.860968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3295</th>\n",
              "      <td>10074</td>\n",
              "      <td>0.962136</td>\n",
              "      <td>0.831715</td>\n",
              "      <td>0.130421</td>\n",
              "      <td>0.987694</td>\n",
              "      <td>0.957609</td>\n",
              "      <td>0.026537</td>\n",
              "      <td>0.905922</td>\n",
              "      <td>0.957609</td>\n",
              "      <td>0.026537</td>\n",
              "      <td>...</td>\n",
              "      <td>0.902866</td>\n",
              "      <td>0.056958</td>\n",
              "      <td>0.798384</td>\n",
              "      <td>0.902866</td>\n",
              "      <td>0.056958</td>\n",
              "      <td>0.798384</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.952412</td>\n",
              "      <td>0.023948</td>\n",
              "      <td>0.913788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3296</th>\n",
              "      <td>10075</td>\n",
              "      <td>0.968608</td>\n",
              "      <td>0.918447</td>\n",
              "      <td>0.050162</td>\n",
              "      <td>0.987694</td>\n",
              "      <td>0.909885</td>\n",
              "      <td>0.025243</td>\n",
              "      <td>0.825828</td>\n",
              "      <td>0.909885</td>\n",
              "      <td>0.025243</td>\n",
              "      <td>...</td>\n",
              "      <td>0.686802</td>\n",
              "      <td>0.097087</td>\n",
              "      <td>0.365670</td>\n",
              "      <td>0.686802</td>\n",
              "      <td>0.097087</td>\n",
              "      <td>0.365670</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.850311</td>\n",
              "      <td>0.042071</td>\n",
              "      <td>0.707527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3297</th>\n",
              "      <td>10076</td>\n",
              "      <td>0.947977</td>\n",
              "      <td>0.950162</td>\n",
              "      <td>-0.002184</td>\n",
              "      <td>0.987694</td>\n",
              "      <td>0.618161</td>\n",
              "      <td>0.056958</td>\n",
              "      <td>0.332928</td>\n",
              "      <td>0.618161</td>\n",
              "      <td>0.056958</td>\n",
              "      <td>...</td>\n",
              "      <td>0.515800</td>\n",
              "      <td>0.089968</td>\n",
              "      <td>0.032195</td>\n",
              "      <td>0.515800</td>\n",
              "      <td>0.089968</td>\n",
              "      <td>0.032195</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.661059</td>\n",
              "      <td>0.082201</td>\n",
              "      <td>0.271099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3298</th>\n",
              "      <td>10077</td>\n",
              "      <td>0.917476</td>\n",
              "      <td>0.871845</td>\n",
              "      <td>0.045631</td>\n",
              "      <td>0.987694</td>\n",
              "      <td>0.752021</td>\n",
              "      <td>0.094498</td>\n",
              "      <td>0.569704</td>\n",
              "      <td>0.752021</td>\n",
              "      <td>0.094498</td>\n",
              "      <td>...</td>\n",
              "      <td>0.662674</td>\n",
              "      <td>0.144984</td>\n",
              "      <td>0.333980</td>\n",
              "      <td>0.662674</td>\n",
              "      <td>0.144984</td>\n",
              "      <td>0.333980</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.661504</td>\n",
              "      <td>0.113269</td>\n",
              "      <td>0.382769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3299</th>\n",
              "      <td>10079</td>\n",
              "      <td>0.925162</td>\n",
              "      <td>0.919741</td>\n",
              "      <td>0.005421</td>\n",
              "      <td>0.987694</td>\n",
              "      <td>0.711715</td>\n",
              "      <td>0.089968</td>\n",
              "      <td>0.374492</td>\n",
              "      <td>0.711715</td>\n",
              "      <td>0.089968</td>\n",
              "      <td>...</td>\n",
              "      <td>0.609461</td>\n",
              "      <td>0.115858</td>\n",
              "      <td>0.218120</td>\n",
              "      <td>0.609461</td>\n",
              "      <td>0.115858</td>\n",
              "      <td>0.218120</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.762965</td>\n",
              "      <td>0.086731</td>\n",
              "      <td>0.470942</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3291 rows × 111 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35cfbc89-9112-4a9a-8d2e-376336d46272')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35cfbc89-9112-4a9a-8d2e-376336d46272 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35cfbc89-9112-4a9a-8d2e-376336d46272');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "performances = pd.read_csv(\"data_for_task.csv\", index_col=0).dropna(axis=0)\n",
        "performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gB1RPHn6hooa"
      },
      "outputs": [],
      "source": [
        "X = performances.drop([\"average_ensemble\", \"average_mlp\", \"ensemble_mlp_diffn\", \"id\"], axis=1)\n",
        "y = performances[\"ensemble_mlp_diffn\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1MYVXD_Ahooa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "Qf2v2pdbhoob",
        "outputId": "fc805944-42de-4815-f9d1-cc303bb6c5cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      AutoCorrelation  CfsSubsetEval_DecisionStumpAUC  \\\n",
              "2994         0.150943                        0.936596   \n",
              "3254         0.172230                        0.502010   \n",
              "3256         0.272975                        0.597146   \n",
              "439          0.713073                        0.948746   \n",
              "2668         0.901042                        0.980657   \n",
              "...               ...                             ...   \n",
              "1101         0.528529                        0.837483   \n",
              "1136         0.511013                        0.984985   \n",
              "1300         0.926357                        0.716137   \n",
              "866          0.886502                        0.928864   \n",
              "3183         0.995498                        0.911420   \n",
              "\n",
              "      CfsSubsetEval_DecisionStumpErrRate  CfsSubsetEval_DecisionStumpKappa  \\\n",
              "2994                            0.140580                          0.837037   \n",
              "3254                            0.778667                          0.007788   \n",
              "3256                            0.691818                          0.097202   \n",
              "439                             0.056481                          0.866635   \n",
              "2668                            0.020725                          0.955174   \n",
              "...                                  ...                               ...   \n",
              "1101                            0.184000                          0.631971   \n",
              "1136                            0.013158                          0.973684   \n",
              "1300                            0.158301                          0.507308   \n",
              "866                             0.025186                          0.775972   \n",
              "3183                            0.295000                          0.672222   \n",
              "\n",
              "      CfsSubsetEval_NaiveBayesAUC  CfsSubsetEval_NaiveBayesErrRate  \\\n",
              "2994                     0.936596                         0.140580   \n",
              "3254                     0.502010                         0.778667   \n",
              "3256                     0.597146                         0.691818   \n",
              "439                      0.948746                         0.056481   \n",
              "2668                     0.980657                         0.020725   \n",
              "...                           ...                              ...   \n",
              "1101                     0.837483                         0.184000   \n",
              "1136                     0.984985                         0.013158   \n",
              "1300                     0.716137                         0.158301   \n",
              "866                      0.928864                         0.025186   \n",
              "3183                     0.911420                         0.295000   \n",
              "\n",
              "      CfsSubsetEval_NaiveBayesKappa  CfsSubsetEval_kNN1NAUC  \\\n",
              "2994                       0.837037                0.936596   \n",
              "3254                       0.007788                0.502010   \n",
              "3256                       0.097202                0.597146   \n",
              "439                        0.866635                0.948746   \n",
              "2668                       0.955174                0.980657   \n",
              "...                             ...                     ...   \n",
              "1101                       0.631971                0.837483   \n",
              "1136                       0.973684                0.984985   \n",
              "1300                       0.507308                0.716137   \n",
              "866                        0.775972                0.928864   \n",
              "3183                       0.672222                0.911420   \n",
              "\n",
              "      CfsSubsetEval_kNN1NErrRate  CfsSubsetEval_kNN1NKappa  ...  \\\n",
              "2994                    0.140580                  0.837037  ...   \n",
              "3254                    0.778667                  0.007788  ...   \n",
              "3256                    0.691818                  0.097202  ...   \n",
              "439                     0.056481                  0.866635  ...   \n",
              "2668                    0.020725                  0.955174  ...   \n",
              "...                          ...                       ...  ...   \n",
              "1101                    0.184000                  0.631971  ...   \n",
              "1136                    0.013158                  0.973684  ...   \n",
              "1300                    0.158301                  0.507308  ...   \n",
              "866                     0.025186                  0.775972  ...   \n",
              "3183                    0.295000                  0.672222  ...   \n",
              "\n",
              "      RandomTreeDepth2AUC  RandomTreeDepth2ErrRate  RandomTreeDepth2Kappa  \\\n",
              "2994             0.680085                 0.550725               0.359090   \n",
              "3254             0.499462                 0.856000              -0.001221   \n",
              "3256             0.565464                 0.684545               0.132050   \n",
              "439              0.920075                 0.069540               0.842043   \n",
              "2668             0.940393                 0.051813               0.886484   \n",
              "...                   ...                      ...                    ...   \n",
              "1101             0.659744                 0.340000               0.319565   \n",
              "1136             0.958420                 0.052632               0.894615   \n",
              "1300             0.636032                 0.305019               0.243110   \n",
              "866              0.785261                 0.036585               0.652262   \n",
              "3183             0.816728                 0.334500               0.628333   \n",
              "\n",
              "      RandomTreeDepth3AUC  RandomTreeDepth3ErrRate  RandomTreeDepth3Kappa  \\\n",
              "2994             0.680085                 0.550725               0.359090   \n",
              "3254             0.499462                 0.856000              -0.001221   \n",
              "3256             0.565464                 0.684545               0.132050   \n",
              "439              0.920075                 0.069540               0.842043   \n",
              "2668             0.940393                 0.051813               0.886484   \n",
              "...                   ...                      ...                    ...   \n",
              "1101             0.659744                 0.340000               0.319565   \n",
              "1136             0.958420                 0.052632               0.894615   \n",
              "1300             0.636032                 0.305019               0.243110   \n",
              "866              0.785261                 0.036585               0.652262   \n",
              "3183             0.816728                 0.334500               0.628333   \n",
              "\n",
              "      StdvNominalAttDistinctValues  kNN1NAUC  kNN1NErrRate  kNN1NKappa  \n",
              "2994                      0.000000  0.635559      0.608696    0.273950  \n",
              "3254                      2.872281  0.502117      0.849333    0.002347  \n",
              "3256                      1.224745  0.557488      0.696364    0.115886  \n",
              "439                       0.000000  0.860730      0.123705    0.720661  \n",
              "2668                      0.000000  0.993922      0.005181    0.988757  \n",
              "...                            ...       ...           ...         ...  \n",
              "1101                      0.000000  0.634914      0.365000    0.269796  \n",
              "1136                      0.000000  0.987179      0.013158    0.973684  \n",
              "1300                      0.000000  0.831222      0.193050    0.558954  \n",
              "866                       0.668312  0.789559      0.041092    0.615379  \n",
              "3183                      0.000000  0.822781      0.329500    0.633889  \n",
              "\n",
              "[2632 rows x 107 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58556c18-88c3-4cd4-813d-9de84db73045\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AutoCorrelation</th>\n",
              "      <th>CfsSubsetEval_DecisionStumpAUC</th>\n",
              "      <th>CfsSubsetEval_DecisionStumpErrRate</th>\n",
              "      <th>CfsSubsetEval_DecisionStumpKappa</th>\n",
              "      <th>CfsSubsetEval_NaiveBayesAUC</th>\n",
              "      <th>CfsSubsetEval_NaiveBayesErrRate</th>\n",
              "      <th>CfsSubsetEval_NaiveBayesKappa</th>\n",
              "      <th>CfsSubsetEval_kNN1NAUC</th>\n",
              "      <th>CfsSubsetEval_kNN1NErrRate</th>\n",
              "      <th>CfsSubsetEval_kNN1NKappa</th>\n",
              "      <th>...</th>\n",
              "      <th>RandomTreeDepth2AUC</th>\n",
              "      <th>RandomTreeDepth2ErrRate</th>\n",
              "      <th>RandomTreeDepth2Kappa</th>\n",
              "      <th>RandomTreeDepth3AUC</th>\n",
              "      <th>RandomTreeDepth3ErrRate</th>\n",
              "      <th>RandomTreeDepth3Kappa</th>\n",
              "      <th>StdvNominalAttDistinctValues</th>\n",
              "      <th>kNN1NAUC</th>\n",
              "      <th>kNN1NErrRate</th>\n",
              "      <th>kNN1NKappa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2994</th>\n",
              "      <td>0.150943</td>\n",
              "      <td>0.936596</td>\n",
              "      <td>0.140580</td>\n",
              "      <td>0.837037</td>\n",
              "      <td>0.936596</td>\n",
              "      <td>0.140580</td>\n",
              "      <td>0.837037</td>\n",
              "      <td>0.936596</td>\n",
              "      <td>0.140580</td>\n",
              "      <td>0.837037</td>\n",
              "      <td>...</td>\n",
              "      <td>0.680085</td>\n",
              "      <td>0.550725</td>\n",
              "      <td>0.359090</td>\n",
              "      <td>0.680085</td>\n",
              "      <td>0.550725</td>\n",
              "      <td>0.359090</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.635559</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.273950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3254</th>\n",
              "      <td>0.172230</td>\n",
              "      <td>0.502010</td>\n",
              "      <td>0.778667</td>\n",
              "      <td>0.007788</td>\n",
              "      <td>0.502010</td>\n",
              "      <td>0.778667</td>\n",
              "      <td>0.007788</td>\n",
              "      <td>0.502010</td>\n",
              "      <td>0.778667</td>\n",
              "      <td>0.007788</td>\n",
              "      <td>...</td>\n",
              "      <td>0.499462</td>\n",
              "      <td>0.856000</td>\n",
              "      <td>-0.001221</td>\n",
              "      <td>0.499462</td>\n",
              "      <td>0.856000</td>\n",
              "      <td>-0.001221</td>\n",
              "      <td>2.872281</td>\n",
              "      <td>0.502117</td>\n",
              "      <td>0.849333</td>\n",
              "      <td>0.002347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3256</th>\n",
              "      <td>0.272975</td>\n",
              "      <td>0.597146</td>\n",
              "      <td>0.691818</td>\n",
              "      <td>0.097202</td>\n",
              "      <td>0.597146</td>\n",
              "      <td>0.691818</td>\n",
              "      <td>0.097202</td>\n",
              "      <td>0.597146</td>\n",
              "      <td>0.691818</td>\n",
              "      <td>0.097202</td>\n",
              "      <td>...</td>\n",
              "      <td>0.565464</td>\n",
              "      <td>0.684545</td>\n",
              "      <td>0.132050</td>\n",
              "      <td>0.565464</td>\n",
              "      <td>0.684545</td>\n",
              "      <td>0.132050</td>\n",
              "      <td>1.224745</td>\n",
              "      <td>0.557488</td>\n",
              "      <td>0.696364</td>\n",
              "      <td>0.115886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>0.713073</td>\n",
              "      <td>0.948746</td>\n",
              "      <td>0.056481</td>\n",
              "      <td>0.866635</td>\n",
              "      <td>0.948746</td>\n",
              "      <td>0.056481</td>\n",
              "      <td>0.866635</td>\n",
              "      <td>0.948746</td>\n",
              "      <td>0.056481</td>\n",
              "      <td>0.866635</td>\n",
              "      <td>...</td>\n",
              "      <td>0.920075</td>\n",
              "      <td>0.069540</td>\n",
              "      <td>0.842043</td>\n",
              "      <td>0.920075</td>\n",
              "      <td>0.069540</td>\n",
              "      <td>0.842043</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.860730</td>\n",
              "      <td>0.123705</td>\n",
              "      <td>0.720661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2668</th>\n",
              "      <td>0.901042</td>\n",
              "      <td>0.980657</td>\n",
              "      <td>0.020725</td>\n",
              "      <td>0.955174</td>\n",
              "      <td>0.980657</td>\n",
              "      <td>0.020725</td>\n",
              "      <td>0.955174</td>\n",
              "      <td>0.980657</td>\n",
              "      <td>0.020725</td>\n",
              "      <td>0.955174</td>\n",
              "      <td>...</td>\n",
              "      <td>0.940393</td>\n",
              "      <td>0.051813</td>\n",
              "      <td>0.886484</td>\n",
              "      <td>0.940393</td>\n",
              "      <td>0.051813</td>\n",
              "      <td>0.886484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.993922</td>\n",
              "      <td>0.005181</td>\n",
              "      <td>0.988757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1101</th>\n",
              "      <td>0.528529</td>\n",
              "      <td>0.837483</td>\n",
              "      <td>0.184000</td>\n",
              "      <td>0.631971</td>\n",
              "      <td>0.837483</td>\n",
              "      <td>0.184000</td>\n",
              "      <td>0.631971</td>\n",
              "      <td>0.837483</td>\n",
              "      <td>0.184000</td>\n",
              "      <td>0.631971</td>\n",
              "      <td>...</td>\n",
              "      <td>0.659744</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.319565</td>\n",
              "      <td>0.659744</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.319565</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.634914</td>\n",
              "      <td>0.365000</td>\n",
              "      <td>0.269796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1136</th>\n",
              "      <td>0.511013</td>\n",
              "      <td>0.984985</td>\n",
              "      <td>0.013158</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.984985</td>\n",
              "      <td>0.013158</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.984985</td>\n",
              "      <td>0.013158</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.958420</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.894615</td>\n",
              "      <td>0.958420</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.894615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.987179</td>\n",
              "      <td>0.013158</td>\n",
              "      <td>0.973684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1300</th>\n",
              "      <td>0.926357</td>\n",
              "      <td>0.716137</td>\n",
              "      <td>0.158301</td>\n",
              "      <td>0.507308</td>\n",
              "      <td>0.716137</td>\n",
              "      <td>0.158301</td>\n",
              "      <td>0.507308</td>\n",
              "      <td>0.716137</td>\n",
              "      <td>0.158301</td>\n",
              "      <td>0.507308</td>\n",
              "      <td>...</td>\n",
              "      <td>0.636032</td>\n",
              "      <td>0.305019</td>\n",
              "      <td>0.243110</td>\n",
              "      <td>0.636032</td>\n",
              "      <td>0.305019</td>\n",
              "      <td>0.243110</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.831222</td>\n",
              "      <td>0.193050</td>\n",
              "      <td>0.558954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>0.886502</td>\n",
              "      <td>0.928864</td>\n",
              "      <td>0.025186</td>\n",
              "      <td>0.775972</td>\n",
              "      <td>0.928864</td>\n",
              "      <td>0.025186</td>\n",
              "      <td>0.775972</td>\n",
              "      <td>0.928864</td>\n",
              "      <td>0.025186</td>\n",
              "      <td>0.775972</td>\n",
              "      <td>...</td>\n",
              "      <td>0.785261</td>\n",
              "      <td>0.036585</td>\n",
              "      <td>0.652262</td>\n",
              "      <td>0.785261</td>\n",
              "      <td>0.036585</td>\n",
              "      <td>0.652262</td>\n",
              "      <td>0.668312</td>\n",
              "      <td>0.789559</td>\n",
              "      <td>0.041092</td>\n",
              "      <td>0.615379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3183</th>\n",
              "      <td>0.995498</td>\n",
              "      <td>0.911420</td>\n",
              "      <td>0.295000</td>\n",
              "      <td>0.672222</td>\n",
              "      <td>0.911420</td>\n",
              "      <td>0.295000</td>\n",
              "      <td>0.672222</td>\n",
              "      <td>0.911420</td>\n",
              "      <td>0.295000</td>\n",
              "      <td>0.672222</td>\n",
              "      <td>...</td>\n",
              "      <td>0.816728</td>\n",
              "      <td>0.334500</td>\n",
              "      <td>0.628333</td>\n",
              "      <td>0.816728</td>\n",
              "      <td>0.334500</td>\n",
              "      <td>0.628333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.822781</td>\n",
              "      <td>0.329500</td>\n",
              "      <td>0.633889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2632 rows × 107 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58556c18-88c3-4cd4-813d-9de84db73045')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-58556c18-88c3-4cd4-813d-9de84db73045 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-58556c18-88c3-4cd4-813d-9de84db73045');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4sWHFHGhoob",
        "outputId": "b0484bf4-f487-439e-ee11-6acbf0445a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "CatBoost obtained an R2 score of 0.6693652427723253\n"
          ]
        }
      ],
      "source": [
        "model = catboost.CatBoostRegressor()\n",
        "model.fit(X_train, y_train, verbose=0)\n",
        "print(f\"\\n\\nCatBoost obtained an R2 score of {model.score(X_test, y_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "2gSxltauhooc",
        "outputId": "66e273b4-25f3-4c8c-9f72-1e2f8f8b2cee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe93a44cd90>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "pd.DataFrame(zip(X_train.columns,model.feature_importances_), columns=[\"feature\", \"importance\"]).sort_values(\"importance\", ascending=False).iloc[:20].plot.bar(x=\"feature\", y=\"importance\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "itsvnYpEhood"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "normalizer = keras.layers.Normalization(axis=-1, name='normalizer')\n",
        "normalizer.adapt(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBhiWtVOhooe",
        "outputId": "1f560ce7-8c92-4fa3-dc56-154dd5b8c3fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalizer (Normalization)  (None, 107)               215       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               13824     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 80,088\n",
            "Trainable params: 79,873\n",
            "Non-trainable params: 215\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
        "    normalizer,\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", )\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2e0cIx7hoof",
        "outputId": "09313d4e-f916-4b5c-9add-4e4a29791b61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "43/43 [==============================] - 1s 7ms/step - loss: 0.0847 - val_loss: 0.0154\n",
            "Epoch 2/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0308 - val_loss: 0.0160\n",
            "Epoch 3/50\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0143\n",
            "Epoch 4/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0225 - val_loss: 0.0070\n",
            "Epoch 5/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0056\n",
            "Epoch 6/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0060\n",
            "Epoch 7/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0060\n",
            "Epoch 8/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0062\n",
            "Epoch 9/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0055\n",
            "Epoch 10/50\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0054\n",
            "Epoch 11/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0056\n",
            "Epoch 12/50\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0059\n",
            "Epoch 13/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0058\n",
            "Epoch 14/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0056\n",
            "Epoch 15/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0054\n",
            "Epoch 16/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0046\n",
            "Epoch 17/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0055\n",
            "Epoch 18/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0049\n",
            "Epoch 19/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0054\n",
            "Epoch 20/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0054\n",
            "Epoch 21/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0051\n",
            "Epoch 22/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0046\n",
            "Epoch 23/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0046\n",
            "Epoch 24/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0052\n",
            "Epoch 25/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0045\n",
            "Epoch 26/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0047\n",
            "Epoch 27/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0045\n",
            "Epoch 28/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0044\n",
            "Epoch 29/50\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0047\n",
            "Epoch 30/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0047\n",
            "Epoch 31/50\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0049\n",
            "Epoch 32/50\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0049\n",
            "Epoch 33/50\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0048\n",
            "Epoch 34/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0044\n",
            "Epoch 35/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0045\n",
            "Epoch 36/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0045\n",
            "Epoch 37/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0040\n",
            "Epoch 38/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0039\n",
            "Epoch 39/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0044\n",
            "Epoch 40/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0035\n",
            "Epoch 41/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0044\n",
            "Epoch 42/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0048\n",
            "Epoch 43/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0044\n",
            "Epoch 44/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0036\n",
            "Epoch 45/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0044\n",
            "Epoch 46/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0046\n",
            "Epoch 47/50\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0043\n",
            "Epoch 48/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0042\n",
            "Epoch 49/50\n",
            "43/43 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 50/50\n",
            "43/43 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0041\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit(X_train, y_train, epochs=50, batch_size=50, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lv5yRKQvVmO",
        "outputId": "801b08f0-6681-4db6-f095-eb9462e8088e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.16.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8jhlBCbhoof",
        "outputId": "949fbda7-cb8a-4390-d0ed-aec9a9911721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 254 Complete [00h 00m 30s]\n",
            "r_square: 0.5637904405593872\n",
            "\n",
            "Best r_square So Far: 0.7047700881958008\n",
            "Total elapsed time: 00h 22m 40s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ],
      "source": [
        "import keras_tuner as kt\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape=(X_train.shape[1],)))\n",
        "    model.add(normalizer)\n",
        "    for n_layer in range(hp.Int('n_layers', 1, 6, default=2)):\n",
        "        model.add(keras.layers.Dense(hp.Int('n_units_'+str(n_layer), 1, 512), activation=hp.Choice('activation', ['relu', 'sigmoid', 'tanh'])))\n",
        "        model.add(keras.layers.Dropout(hp.Float('dropout_'+str(n_layer), 0, 0.5, step=0.05)))\n",
        "    model.add(keras.layers.Dense(1))\n",
        "    model.compile(loss='mse', optimizer='adam', metrics=[tfa.metrics.RSquare(dtype=tf.float32, y_shape=(1,))])\n",
        "    return model\n",
        "\n",
        "tuner = kt.Hyperband(build_model,\n",
        "                        objective=kt.Objective(\"r_square\", \"max\"),\n",
        "                        max_epochs=100,\n",
        "                        directory='/tmp/keras_tuner',\n",
        "                        project_name='lastduel',\n",
        "                        overwrite=True)\n",
        "tuner.search(X_train, y_train, epochs=10, validation_split=0.2) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_Ncr71Oqhoog"
      },
      "outputs": [],
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "best_model.save('best_model_h5', save_format='h5')\n",
        "files.download('best_model_h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "E7W9Xr7LsLhP",
        "outputId": "52049a41-c33b-4127-ce60-2a98a53024db"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_548e9cd3-4c2b-4cb6-a138-ccfc8b8910b2\", \"best_model_h5\", 7050076)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z0iokxEhoog",
        "outputId": "e1a3a732-8c23-4bc9-f0ae-e482fe930438"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.00385789323120996, 0.6142371867666576)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "mean_squared_error(y_test, best_model.predict(X_test)), r2_score(y_test, best_model.predict(X_test))"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "503283322573d37c56bdddf48cefc755e7d6e72fbbf6e2a45e8759e4dfccb923"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('tesi')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}